{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 : tensorflow.keras 공식 문서 (Official API Docs) @ https://www.tensorflow.org/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"../Blank file & Answer files/titanic.csv\")\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>isAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked  Title  FamilySize  isAlone\n",
       "0         0       3    0  1.0   0.0         0      3         0.4        0\n",
       "1         1       1    1  2.0   0.0         2      4         0.4        0\n",
       "2         1       3    1  1.0   0.0         0      2         0.0        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del titanic_df['Cabin'] # 너무 많은 결측치가 존재\n",
    "del titanic_df['PassengerId'] # Passenger 번호는 큰 의미를 갖고있지 않은 일련번호\n",
    "del titanic_df['Ticket'] # ticket 번호에서 패턴이 확인되지 않음\n",
    "\n",
    "\n",
    "titanic_df['Title'] = titanic_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "del titanic_df['Name'] # 호칭만 남김\n",
    "\n",
    "rare_title = []\n",
    "for title in set(titanic_df['Title']):\n",
    "    if list(titanic_df['Title']).count(title) < 10:\n",
    "        rare_title.append(title)\n",
    "\n",
    "titanic_df['Title'] = titanic_df['Title'].replace('Mlle', 'Miss') # Mademoiselle\n",
    "titanic_df['Title'] = titanic_df['Title'].replace('Ms', 'Miss') \n",
    "titanic_df['Title'] = titanic_df['Title'].replace('Mme', 'Mrs') # Madame\n",
    "titanic_df['Title'] = titanic_df['Title'].replace(rare_title, 'Rare')\n",
    "\n",
    "title_mapping = {\"Master\":1, \"Miss\":2, \"Mr\":3, \"Mrs\":4, \"Rare\":5 }\n",
    "titanic_df['Title'] = titanic_df['Title'].map(title_mapping)\n",
    "titanic_df['Title'] = titanic_df['Title'].fillna(0)\n",
    "titanic_df['Title'].astype(int)\n",
    "\n",
    "\n",
    "sex_mapping = {\"male\": 0 , \"female\":1} \n",
    "titanic_df['Sex'] = titanic_df['Sex'].map(sex_mapping)\n",
    "\n",
    "\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna('S')\n",
    "mapping_data ={\"S\":0, \"Q\":1, \"C\":2}\n",
    "titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].map(mapping_data)\n",
    "\n",
    "\n",
    "titanic_df.loc[ titanic_df['Fare'] <= 102, 'Fare'] = 0\n",
    "titanic_df.loc[(titanic_df['Fare'] > 102) & (titanic_df['Fare'] <= 204), 'Fare'] = 1\n",
    "titanic_df.loc[(titanic_df['Fare'] > 204) & (titanic_df['Fare'] <= 307), 'Fare'] = 2\n",
    "titanic_df.loc[ titanic_df['Fare'] > 307, 'Fare'] = 4\n",
    "\n",
    "\n",
    "titanic_df[\"FamilySize\"] = titanic_df[\"SibSp\"] + titanic_df[\"Parch\"] +1\n",
    "del titanic_df['SibSp']\n",
    "del titanic_df['Parch']\n",
    "\n",
    "titanic_df['isAlone'] = 0\n",
    "titanic_df.loc[titanic_df['FamilySize'] == 1, 'isAlone'] = 1\n",
    "\n",
    "family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "titanic_df['FamilySize'] = titanic_df['FamilySize'].map(family_mapping)\n",
    "\n",
    "\n",
    "titanic_df[\"Age\"].fillna(titanic_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "titanic_df.loc[ titanic_df['Age'] <= 16, 'Age'] = 0\n",
    "titanic_df.loc[(titanic_df['Age'] > 16) & (titanic_df['Age'] <= 32), 'Age'] = 1\n",
    "titanic_df.loc[(titanic_df['Age'] > 32) & (titanic_df['Age'] <= 48), 'Age'] = 2\n",
    "titanic_df.loc[(titanic_df['Age'] > 48) & (titanic_df['Age'] <= 64), 'Age'] = 3\n",
    "titanic_df.loc[ titanic_df['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Devide dataframe into X & Y -> Train X / Test X / Train Y / Test Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_target = titanic_df[['Survived']].copy()\n",
    "titanic_data = titanic_df.copy()\n",
    "\n",
    "del titanic_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 8)\n",
      "(268, 8)\n",
      "(623, 1)\n",
      "(268, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_label, test_label = model_selection.train_test_split(titanic_data, titanic_target,\n",
    "                                                                                 test_size=0.3,\n",
    "                                                                                 random_state=0)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Change normal labels to one-hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "857         1\n",
       "52          1\n",
       "386         0\n",
       "124         0\n",
       "578         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 2)\n",
      "(268, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "train_label = utils.to_categorical(train_label) # 0 or 1 -> one-hot vector\n",
    "test_label = utils.to_categorical(test_label) # 0 or 1 -> one-hot vector\n",
    "\n",
    "print(train_label.shape) # 모양을 영어로?\n",
    "print(test_label.shape) # 모양을 영어로?\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# enc = preprocessing.OneHotEncoder(categories='auto') # Apply 'One-hot encoding' on labels (Single integer to One-hot vector)\n",
    "# train_label = enc.fit_transform(train_label).toarray()\n",
    "# test_label = enc.fit_transform(test_label).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. Build & Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.keras 에 필요한 함수들이 모여있습니다.\n",
    "from tensorflow.keras import datasets, utils\n",
    "from tensorflow.keras import models, layers, activations, initializers, losses, optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.cvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() # Build up the \"Sequence\" of layers (Linear stack of layers)\n",
    "\n",
    "# Dense-layer (with he-initialization)\n",
    "model.add(layers.Dense(input_dim=len(titanic_data.columns), units=256, activation=None, kernel_initializer=initializers.he_uniform())) # he-uniform initialization\n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('elu')) # elu or relu (or layers.ELU / layers.LeakyReLU)\n",
    "\n",
    "model.add(layers.Dense(units=512, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu')) \n",
    "\n",
    "model.add(layers.Dense(units=512, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dense(units=256, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu')) \n",
    "model.add(layers.Dropout(rate=0.5)) # Dropout-layer\n",
    "\n",
    "model.add(layers.Dense(units=2, activation='softmax')) # Apply softmax function on model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Compile\" the model description (Configures the model for training)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(), # Please try the Adam-optimizer\n",
    "              loss=losses.categorical_crossentropy, \n",
    "              metrics=[metrics.Recall(), metrics.Precision()]) # Precision / Recall / F1-Score 적용하기 @ https://j.mp/3cf3lbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.callbacks.ModelCheckpoint(3-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 68ms/step - loss: 3.3846 - recall: 0.5436 - precision: 0.5436 - val_loss: 1.6154 - val_recall: 0.6631 - val_precision: 0.6631\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9019 - recall: 0.7179 - precision: 0.7179 - val_loss: 0.5534 - val_recall: 0.7807 - val_precision: 0.7807\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1053 - recall: 0.6651 - precision: 0.6651 - val_loss: 0.6445 - val_recall: 0.7487 - val_precision: 0.7487\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7326 - recall: 0.7317 - precision: 0.7317 - val_loss: 0.4083 - val_recall: 0.8342 - val_precision: 0.8342\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7395 - recall: 0.7339 - precision: 0.7339 - val_loss: 0.5693 - val_recall: 0.7754 - val_precision: 0.7754\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6137 - recall: 0.7523 - precision: 0.7523 - val_loss: 0.4646 - val_recall: 0.8021 - val_precision: 0.8021\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5729 - recall: 0.7890 - precision: 0.7890 - val_loss: 0.4806 - val_recall: 0.8128 - val_precision: 0.8128\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5415 - recall: 0.8119 - precision: 0.8119 - val_loss: 0.5100 - val_recall: 0.8182 - val_precision: 0.8182\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5706 - recall: 0.8028 - precision: 0.8028 - val_loss: 0.4552 - val_recall: 0.8182 - val_precision: 0.8182\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5690 - recall: 0.7775 - precision: 0.7775 - val_loss: 0.5524 - val_recall: 0.7540 - val_precision: 0.7540\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5354 - recall: 0.7775 - precision: 0.7775 - val_loss: 0.4674 - val_recall: 0.8396 - val_precision: 0.8396\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6159 - recall: 0.7844 - precision: 0.7844 - val_loss: 0.5073 - val_recall: 0.8289 - val_precision: 0.8289\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5635 - recall: 0.8119 - precision: 0.8119 - val_loss: 0.6093 - val_recall: 0.7968 - val_precision: 0.7968\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5465 - recall: 0.7959 - precision: 0.7959 - val_loss: 0.5046 - val_recall: 0.7914 - val_precision: 0.7914\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6115 - recall: 0.7317 - precision: 0.7317 - val_loss: 0.7057 - val_recall: 0.7166 - val_precision: 0.7166\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5858 - recall: 0.8050 - precision: 0.8050 - val_loss: 0.4396 - val_recall: 0.8396 - val_precision: 0.8396\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5443 - recall: 0.8050 - precision: 0.8050 - val_loss: 0.5964 - val_recall: 0.7433 - val_precision: 0.7433\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5847 - recall: 0.7844 - precision: 0.7844 - val_loss: 0.4577 - val_recall: 0.8075 - val_precision: 0.8075\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4924 - recall: 0.8326 - precision: 0.8326 - val_loss: 0.5768 - val_recall: 0.7914 - val_precision: 0.7914\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5365 - recall: 0.7913 - precision: 0.7913 - val_loss: 0.4556 - val_recall: 0.8128 - val_precision: 0.8128\n"
     ]
    }
   ],
   "source": [
    "# \"Fit\" the model on training data\n",
    "\n",
    "history = model.fit(train_data, train_label, batch_size=100, epochs=20, validation_split=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4506 - recall: 0.8172 - precision: 0.8172\n",
      "loss (cross-entropy) : 0.45061469078063965\n",
      "test accuracy : 0.8171641826629639\n"
     ]
    }
   ],
   "source": [
    "# \"Evaluate\" the model on test data\n",
    "\n",
    "result = model.evaluate(test_data, test_label)\n",
    "\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'recall', 'precision', 'val_loss', 'val_recall', 'val_precision'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'recall_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_recall_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m x_len \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(acc))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recall_1'"
     ]
    }
   ],
   "source": [
    "acc = history.history['recall_1']\n",
    "val_acc = history.history['val_recall_1']\n",
    "\n",
    "x_len = np.arange(len(acc))\n",
    "\n",
    "plt.plot(x_len, acc, marker='.', c='blue', label=\"Train-set Acc.\")\n",
    "plt.plot(x_len, val_acc, marker='.', c='red', label=\"Validation-set Acc.\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['recall_1']\n",
    "val_loss = history.history['val_recall_1']\n",
    "\n",
    "x_len = np.arange(len(acc))\n",
    "\n",
    "plt.plot(x_len, loss, marker='.', c='blue', label=\"Train-set loss.\")\n",
    "plt.plot(x_len, val_loss, marker='.', c='red', label=\"Validation-set loss.\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cross-entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Predict' on test data\n",
    "\n",
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(test_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = np.array([[3, 0, 0.0, 0.0, 1, 1, 2.0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_put layout의 확률 : 죽었을 확률/ 살았을 확률\n",
    "model.predict(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(sample_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
