{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import rc\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "rc('font', family='Malgun Gothic') # Windows OS \n",
    "# rc('font', family='AppleGothic') # os x(mac os)  \n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\") # 그래프를 격자 스타일로 (숫자 범위가 눈에 잘 띄도록 ggplot 스타일 사용.)\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False # 그래프에서 마이너스 폰트 깨지는 문제 해결을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>isAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Embarked  Title  FamilySize  isAlone\n",
       "0         0       3    0  22.0   7.2500         0      3           2        0\n",
       "1         1       1    1  38.0  71.2833         2      4           2        0\n",
       "2         1       3    1  26.0   7.9250         0      2           1        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "\n",
    "del titanic_df['Cabin'] # 너무 많은 결측치가 존재\n",
    "del titanic_df['PassengerId'] # Passenger 번호는 큰 의미를 갖고있지 않은 일련번호\n",
    "del titanic_df['Ticket'] # ticket 번호에서 패턴이 확인되지 않음\n",
    "\n",
    "\n",
    "titanic_df['Title'] = titanic_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "rare_title = []\n",
    "for title in set(titanic_df['Title']):\n",
    "    if list(titanic_df['Title']).count(title) < 10:\n",
    "        rare_title.append(title)\n",
    "\n",
    "titanic_df['Title'] = titanic_df['Title'].replace('Mlle', 'Miss') # Mademoiselle\n",
    "titanic_df['Title'] = titanic_df['Title'].replace('Ms', 'Miss') \n",
    "titanic_df['Title'] = titanic_df['Title'].replace('Mme', 'Mrs') # Madame\n",
    "titanic_df['Title'] = titanic_df['Title'].replace(rare_title, 'Rare')\n",
    "\n",
    "del titanic_df['Name'] # 호칭만 남김\n",
    "\n",
    "title_mapping = {\"Master\":1, \"Miss\":2, \"Mr\":3, \"Mrs\":4, \"Rare\":5 }\n",
    "\n",
    "titanic_df['Title'] = titanic_df['Title'].map(title_mapping)\n",
    "titanic_df['Title'] = titanic_df['Title'].fillna(0)\n",
    "titanic_df['Title'].astype(int)\n",
    "\n",
    "\n",
    "sex_mapping = {\"male\": 0 , \"female\":1} \n",
    "titanic_df['Sex'] = titanic_df['Sex'].map(sex_mapping)\n",
    "\n",
    "\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna('S')\n",
    "\n",
    "mapping_data ={\"S\":0, \"Q\":1, \"C\":2}\n",
    "titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].map(mapping_data)\n",
    "\n",
    "\n",
    "# titanic_df[\"Fareband\"] = pd.cut(titanic_df[\"Fare\"], 5) # Bin values into discrete intervals.\n",
    "# titanic_df[['Fareband','Survived']].groupby('Fareband').mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "# del titanic_df['Fareband']\n",
    "\n",
    "# titanic_df.loc[ titanic_df['Fare'] <= 102, 'Fare'] = 0,\n",
    "# titanic_df.loc[(titanic_df['Fare'] > 102) & (titanic_df['Fare'] <= 204), 'Fare'] = 1,\n",
    "# titanic_df.loc[(titanic_df['Fare'] > 204) & (titanic_df['Fare'] <= 307), 'Fare'] = 2,\n",
    "# titanic_df.loc[ titanic_df['Fare'] > 307, 'Fare'] = 4\n",
    "\n",
    "\n",
    "titanic_df[\"FamilySize\"] = titanic_df[\"SibSp\"] + titanic_df[\"Parch\"] +1\n",
    "\n",
    "titanic_df['isAlone'] = 0\n",
    "titanic_df.loc[titanic_df['FamilySize'] == 1, 'isAlone'] = 1\n",
    "\n",
    "del titanic_df['SibSp']\n",
    "del titanic_df['Parch']\n",
    "\n",
    "# family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "# titanic_df['FamilySize'] = titanic_df['FamilySize'].map(family_mapping)\n",
    "\n",
    "\n",
    "titanic_df[\"Age\"].fillna(titanic_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "## 결측치를 별도의 머신러닝 모델을 만들어 채워넣을 수도 있음\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# titanic_df[\"Age\"].fillna(0, inplace=True)\n",
    "# f_columns = ['Pclass', 'Sex', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
    "# AgeNull = titanic_df[titanic_df['Age']==0]\n",
    "# AgeNotNull = titanic_df[titanic_df['Age']!=0]\n",
    "# X_train = AgeNotNull[f_columns]\n",
    "\n",
    "# random_forest = RandomForestRegressor(n_estimators=200)\n",
    "# random_forest.fit(X_train, AgeNotNull[\"Age\"]) # 나이 정보가 있는 열로 나이 열을 맞추기 위한 모델을 학습\n",
    "\n",
    "# train_pred = random_forest.predict(AgeNull[f_columns])\n",
    "# AgeNull[\"Age\"]= train_pred\n",
    "\n",
    "# titanic_df = AgeNotNull.append(AgeNull)\n",
    "\n",
    "\n",
    "# titanic_df['AgeBand'] = pd.cut(titanic_df['Age'], 5)\n",
    "# titanic_df[['AgeBand', 'Survived']].groupby('AgeBand', as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n",
    "\n",
    "# del titanic_df['AgeBand']\n",
    "\n",
    "# titanic_df.loc[ titanic_df['Age'] <= 16, 'Age'] = 0,\n",
    "# titanic_df.loc[(titanic_df['Age'] > 16) & (titanic_df['Age'] <= 32), 'Age'] = 1,\n",
    "# titanic_df.loc[(titanic_df['Age'] > 32) & (titanic_df['Age'] <= 48), 'Age'] = 2,\n",
    "# titanic_df.loc[(titanic_df['Age'] > 48) & (titanic_df['Age'] <= 64), 'Age'] = 3,\n",
    "# titanic_df.loc[ titanic_df['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Age : 구간화 제외됨\n",
    "### - Fare : 구간화 제외됨\n",
    "### - FamilySize : Re-scaling 제외됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 2. X-Y Split & Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_target = titanic_df['Survived'].copy()\n",
    "titanic_data = titanic_df.copy()\n",
    "del titanic_data['Survived']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(titanic_data, titanic_target, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>isAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age     Fare  Embarked  Title  FamilySize  isAlone\n",
       "857       1    0  51.0  26.5500         0      3           1        1\n",
       "52        1    1  49.0  76.7292         2      4           2        0\n",
       "386       3    0   1.0  46.9000         0      1           8        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 3. Make Pipeline for feature-transformer (StandardScaler & OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'FamilySize', 'isAlone']\n",
    "categorical_transformer = OneHotEncoder(categories='auto') # categories='auto' : just for ignoring warning messages\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ # List of (name, transformer, column(s))\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_pipe = Pipeline(steps=[('ColumnTransform', preprocessor)]) # preprocessing-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ColumnTransform',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['Age', 'Fare']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['Pclass', 'Sex', 'Embarked',\n",
       "                                                   'Title', 'FamilySize',\n",
       "                                                   'isAlone'])]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_pipe.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed = preprocessor_pipe.transform(x_train)\n",
    "x_test_transformed = preprocessor_pipe.transform(x_test)\n",
    "\n",
    "# 위에서 categorical_features 리스트에 포함시킨 열 중 숫자가 아닌 텍스트(문자열)로 이루어진 열이 있을 경우,\n",
    "# .transform() 함수 실행 결과로 만들어진 변수의 타입이 np.array가 아닌 csr_matrix일 수 있습니다.\n",
    "# 그 경우에는 .tranform() 함수 실행 직후 .todense() 함수를 추가로 실행해주시면 됩니다.\n",
    "\n",
    "# ex) preprocessor_pipe.transform(x_train).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.615889</td>\n",
       "      <td>-0.122530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.465287</td>\n",
       "      <td>0.918124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.149160</td>\n",
       "      <td>0.299503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2    3    4    5    6    7    8    9   ...   16   17  \\\n",
       "0  1.615889 -0.122530  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "1  1.465287  0.918124  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  ...  1.0  0.0   \n",
       "2 -2.149160  0.299503  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "    18   19   20   21   22   23   24   25  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train_transformed).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 같이 Pipeline을 통해 preprocessing을 진행할 경우,\n",
    "# inverse_transform은 작동하지 않습니다. (이후 새로운 데이터가 들어올 경우 전처리 -> predict만 수행)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 4. Training with single model (without Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.8284\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_transformed, y_train)\n",
    "\n",
    "accuracy = model.score(x_test_transformed, y_test)\n",
    "print(\"model score:\", round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 5. Training with multiple models (without Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(solver='lbfgs'),\n",
    "          KNeighborsClassifier(n_neighbors=20),\n",
    "          DecisionTreeClassifier(),\n",
    "          ExtraTreeClassifier(),\n",
    "          AdaBoostClassifier(),\n",
    "          RandomForestClassifier(n_estimators=200),\n",
    "          GradientBoostingClassifier(n_estimators=200),\n",
    "          SVC(gamma='auto')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: LogisticRe ...\n",
      "model score: 0.8284\n",
      "\n",
      "model name: KNeighbors ...\n",
      "model score: 0.806\n",
      "\n",
      "model name: DecisionTr ...\n",
      "model score: 0.7761\n",
      "\n",
      "model name: ExtraTreeC ...\n",
      "model score: 0.7276\n",
      "\n",
      "model name: AdaBoostCl ...\n",
      "model score: 0.8209\n",
      "\n",
      "model name: RandomFore ...\n",
      "model score: 0.7948\n",
      "\n",
      "model name: GradientBo ...\n",
      "model score: 0.8284\n",
      "\n",
      "model name: SVC(gamma= ...\n",
      "model score: 0.8209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can make following codes as a function.\n",
    "# You can show the result knittly as a DataFrame.\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    model.fit(x_train_transformed, y_train)\n",
    "    accuracy = model.score(x_test_transformed, y_test)\n",
    "    \n",
    "    print(\"model name:\", model.__str__()[:10], '...')\n",
    "    print(\"model score:\", round(accuracy, 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 6. Go deep with Hyper-params (without Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=200, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.8358\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "\n",
    "accuracy = model.score(x_test, y_test)\n",
    "print(\"model score:\", round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best params: {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 200, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['deviance', 'exponential'], # you can exclude \"deviance\" \n",
    "    'learning_rate': [0.01, 0.001], # you can exclude \"0.001\" \n",
    "    'n_estimators': [200, 500], # 500, 1000, 1500\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'random_state': [0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, \n",
    "                           refit=True, cv=3, n_jobs=1, verbose=1, scoring= 'accuracy')\n",
    "\n",
    "grid_search.fit(x_train_transformed, y_train)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2603027820587158"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.refit_time_ # Seconds used for refitting the best model on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.8284\n"
     ]
    }
   ],
   "source": [
    "accuracy = grid_search.score(x_test_transformed, y_test)\n",
    "print(\"model score:\", round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "#                                    loss='exponential', \n",
    "#                                    max_depth=4, \n",
    "#                                    min_samples_split=2, \n",
    "#                                    n_estimators=200, \n",
    "#                                    random_state=0)\n",
    "\n",
    "# model.fit(x_train_transformed, y_train)\n",
    "\n",
    "# accuracy = model.score(x_test_transformed, y_test)\n",
    "# print(\"model score:\", round(accuracy, 4))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
